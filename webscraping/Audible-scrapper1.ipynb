{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web scraping script #1: fetching metadata from Audible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pickle\n",
    "from re import search\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories='https://www.audible.com/categories'\n",
    "page=requests.get(categories)\n",
    "categories_page= BeautifulSoup(page.content, 'html.parser')\n",
    "aud_key='https://www.audible.com'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_categories(categories_page):\n",
    "    '''\n",
    "    function to get all categories and sub-categories\n",
    "    '''\n",
    "    categories=[a for a in categories_page.findAll(\"div\",{\"class\":\"bc-col-responsive singleCategoryContainer bc-col-3\"})]\n",
    "    major_categories=dict()\n",
    "    for i in categories:\n",
    "        cat=i.findAll(\"a\",{\"class\":\"bc-link categoryLink bc-color-link\"})[0].contents[0]\n",
    "        subcat=i.findAll(\"a\",{\"class\":\"bc-link subCategoryLink bc-color-link\"})\n",
    "        major_categories[cat]=[]\n",
    "        for n in subcat:\n",
    "            web=aud_key+n['href']\n",
    "            try:\n",
    "                page=requests.get(web)\n",
    "            except:\n",
    "                try:\n",
    "                    time.sleep(0.5)\n",
    "                    page=requests.get(web)\n",
    "                except:\n",
    "                    pass\n",
    "            sub_cat_page=BeautifulSoup(page.content, 'html.parser')\n",
    "            all_books_link=get_all_books_subcat(sub_cat_page)\n",
    "            major_categories[cat].append((all_books_link,n.contents[0]))\n",
    "            #print ((all_books_link,n.contents[0]))\n",
    "    return major_categories    \n",
    "\n",
    "def get_node_id(major_categories):\n",
    "    '''\n",
    "    function to get audible keys for all categories and sub-categories\n",
    "    '''\n",
    "    node_categories=dict()\n",
    "    for key,val in major_categories.items():\n",
    "        node_categories[key]=[]\n",
    "        for item in val:\n",
    "            item_n=item[0].split('?')[-1].split('=')[-1]\n",
    "            node_categories[key].append((item_n,item[1]))\n",
    "    return node_categories\n",
    "\n",
    "def get_all_books_subcat(sub_cat_page):\n",
    "    all_books=sub_cat_page.find(\"div\",{\"class\":'bc-col-responsive bc-text-right bc-col-4'}).find('a',{'class':'bc-link allInCategoryPageLink bc-color-link'})['href']\n",
    "    return all_books\n",
    "\n",
    "def get_dataframe(major_categories):\n",
    "    '''\n",
    "    get one large dataframe with all 22MB data\n",
    "    '''\n",
    "    lst=[]\n",
    "    for key,val in major_categories.items():\n",
    "        type_name=key\n",
    "        for subtype in val:\n",
    "            node=str(subtype[0])\n",
    "            subtype_name=subtype[1]\n",
    "            for page in range(0,25):\n",
    "                weblink='https://www.audible.com/search?ref=a_search_c1_sort_5&pf_rd_p=073d8370-97e5-4b7b-be04-aa06cf22d7dd&pf_rd_r=QM0BY2YEWDHNKGKHYKAK&node='+node+'&feature_six_browse-bin=18685580011&feature_twelve_browse-bin=18685552011&sort=review-rank&pageSize=50&page='+str(page)\n",
    "                try:\n",
    "                    subtype_page=requests.get(weblink)\n",
    "                except:\n",
    "                    try:\n",
    "                        time.sleep(0.5)\n",
    "                        subtype_page=requests.get(weblink)\n",
    "                    except:\n",
    "                        pass\n",
    "                sub_cat_page= BeautifulSoup(subtype_page.content, 'html.parser')\n",
    "                #print (\"Fetching information for %s category, %s sub category, %d page\"%(type_name,subtype_name,page))\n",
    "                lst=get_information_from_a_page(sub_cat_page,type_name,subtype_name,lst,page)\n",
    "                \n",
    "    final_df=pd.DataFrame(lst, columns=['Category','Sub Category','Book Name',\\\n",
    "                              'Book Link','Subtitle','Author Names','Narrator Names',\\\n",
    "                              'Runtime','Release Date','Ratings','Reviewers'])\n",
    "    final_df.drop_duplicates(inplace=True).reset_index(inplace=True)\n",
    "    return final_df\n",
    "\n",
    "def save_data_by_cat(major_categories,category):\n",
    "    '''\n",
    "    get data for each catehory and save to csv\n",
    "    '''\n",
    "    lst=[];val=major_categories[category]\n",
    "    type_name=category\n",
    "    for subtype in val:\n",
    "        node=str(subtype[0])\n",
    "        subtype_name=subtype[1]\n",
    "        for page in range(0,25):\n",
    "            weblink='https://www.audible.com/search?ref=a_search_c1_sort_5&pf_rd_p=073d8370-97e5-4b7b-be04-aa06cf22d7dd&pf_rd_r=QM0BY2YEWDHNKGKHYKAK&node='+node+'&feature_six_browse-bin=18685580011&feature_twelve_browse-bin=18685552011&sort=review-rank&pageSize=50&page='+str(page)\n",
    "            try:\n",
    "                subtype_page=requests.get(weblink)\n",
    "            except:\n",
    "                try:\n",
    "                    time.sleep(0.5)\n",
    "                    subtype_page=requests.get(weblink)\n",
    "                except:\n",
    "                    pass\n",
    "            sub_cat_page= BeautifulSoup(subtype_page.content, 'html.parser')\n",
    "                #print (\"Fetching information for %s category, %s sub category, %d page\"%(type_name,subtype_name,page))\n",
    "            lst=get_information_from_a_page(sub_cat_page,type_name,subtype_name,lst,page)\n",
    "                \n",
    "    final_df=pd.DataFrame(lst, columns=['Category','Sub Category','Book Name',\\\n",
    "                              'Book Link','Subtitle','Author Names','Narrator Names',\\\n",
    "                              'Runtime','Release Date','Ratings','Reviewers'])\n",
    "    final_df.drop_duplicates(inplace=True) #.reset_index(inplace=True)\n",
    "    final_df.to_csv(category.replace(\" \", \"\")+'_df.csv')\n",
    "\n",
    "def get_information_from_a_page(sub_cat_page,type_name,subtype_name,lst,page):\n",
    "    '''\n",
    "    given a link, get all relevant metadata from a page\n",
    "    '''\n",
    "    mydivs_page = [[a] for a in sub_cat_page.findAll(\"li\",{\"class\":\"bc-list-item productListItem\"})]             \n",
    "    for i in mydivs_page:\n",
    "        book_name=i[0][\"aria-label\"]\n",
    "        book_link=[b['href'] for a in i[0].findAll(\"li\",{\"class\":'bc-list-item'}) for b in a.findAll(\"a\")][0]\n",
    "        subtitle_list=i[0].find(\"li\",{\"class\":\"bc-list-item subtitle\"})\n",
    "        if subtitle_list:\n",
    "            subtitle_list=subtitle_list.findAll(\"span\")\n",
    "            subtitle=[i.contents[0] for i in subtitle_list][0]\n",
    "        else:\n",
    "            subtitle='None'\n",
    "        author_list=i[0].find(\"li\",{\"class\":\"bc-list-item authorLabel\"}).findAll(\"a\") \n",
    "        author_names=','.join([i.contents[0] for i in author_list])\n",
    "        try:\n",
    "            narrator_list=i[0].find(\"li\",{\"class\":\"bc-list-item narratorLabel\"}).findAll(\"a\") \n",
    "            narrator_names=','.join([i.contents[0] for i in narrator_list])\n",
    "        except:\n",
    "            narrator_names='None'\n",
    "        runtime_list=i[0].find(\"li\",{\"class\":\"bc-list-item runtimeLabel\"}).findAll(\"span\") \n",
    "        runtime=[i.contents[0] for i in runtime_list][0].split(':')[-1]\n",
    "        release_list=i[0].find(\"li\",{\"class\":\"bc-list-item releaseDateLabel\"}).findAll(\"span\") \n",
    "        release=[i.contents[0] for i in release_list][0].split()[-1]\n",
    "        ratings_list=i[0].find(\"li\",{\"class\":\"bc-list-item ratingsLabel\"}).findAll(\"span\",{\"class\":\"bc-text bc-pub-offscreen\"})\n",
    "        rating=[i.contents[0] for i in ratings_list ]\n",
    "        if len(rating)>0:\n",
    "            rate=rating[0][0]\n",
    "        else:\n",
    "            rate='None'\n",
    "        review_list=i[0].find(\"li\",{\"class\":\"bc-list-item ratingsLabel\"}).findAll(\"span\",{\"class\":\"bc-text bc-size-small bc-color-secondary\"})\n",
    "        review=[i.contents[0] for i in review_list][0]\n",
    "        if 'Not rated' in review:\n",
    "            rev='None'\n",
    "        else:\n",
    "            rev=review.split()[0]\n",
    "        lst.append([type_name,subtype_name,book_name,book_link,\\\n",
    "                   subtitle,author_names,narrator_names,runtime,\\\n",
    "                   release,rate,rev])\n",
    "    return lst "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pickle categories information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Arts & Entertainment'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "major_categories=get_all_categories(categories_page)\n",
    "major_categories_node=get_node_id(major_categories)\n",
    "sys.setrecursionlimit(10000)\n",
    "pickle.dump(major_categories_node, open(\"categories.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = open('categories.p','rb')\n",
    "major_categories = pickle.load(infile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write csv for sub categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just wrote file for Science & Engineering\n",
      "Just wrote file for Science Fiction & Fantasy\n",
      "Just wrote file for Sports & Outdoors\n",
      "Just wrote file for Teen & Young Adult\n",
      "Just wrote file for Travel & Tourism\n"
     ]
    }
   ],
   "source": [
    "#test={'Arts & Entertainment': [('18571912011', 'Architecture')]}\n",
    "for item,val in major_categories.items():\n",
    "    get_dataframe_by_cat(major_categories,category=item)\n",
    "    print (\"Just wrote file for %s\"%(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
